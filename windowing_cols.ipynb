{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from category_encoders import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngine:\n",
    "    def __init__(self,):\n",
    "        self.training_set = pd.read_csv(\"cleaned_data/train_data.csv\")\n",
    "        print(self.training_set.iloc[:, 221].isna().sum())\n",
    "        self.validation_set = pd.read_csv(\"cleaned_data/validation_data.csv\")\n",
    "        self.test_set = pd.read_csv(\"cleaned_data/test_data.csv\")\n",
    "        self.demographic_set = pd.read_csv(\"Data Tables/HScreening.txt\", delimiter = '|')\n",
    "        #self.time_series = pd.read_csv(\"Experimental_Notebooks/resampled_day.csv\")\n",
    "        self.aggregate_window(self.tar, \"tar\")\n",
    "        #self.aggregate_window(self.tbr, \"tbr\")\n",
    "        #self.aggregate_window(self.rolling_mean, \"mean\")\n",
    "        #self.aggregate_window(self.rolling_deviation, \"std\")\n",
    "        #self.aggregate_window(self.tir, \"tir\")\n",
    "        #self.aggregate_window(self.fft, \"fft\")\n",
    "        #self.add_demographics()\n",
    "\n",
    "\n",
    "    \n",
    "    def fft(self, arr:np.ndarray) -> np.ndarray:\n",
    "        return fft(arr)\n",
    "    \n",
    "    def rolling_deviation(self, arr:np.ndarray) -> np.ndarray:\n",
    "        return np.std(arr)\n",
    "    \n",
    "    def tar(self, arr: np.ndarray) -> np.ndarray:\n",
    "        mask = arr > 180\n",
    "        return np.mean(mask)\n",
    "    \n",
    "    def tir(self, arr: np.ndarray) -> np.ndarray:\n",
    "        mask = (arr >= 70) & (arr <= 180)\n",
    "        return np.mean(mask)\n",
    "    \n",
    "    def tbr(self, arr: np.ndarray) -> np.ndarray:\n",
    "        mask = arr < 70\n",
    "        return np.mean(mask)\n",
    "    \n",
    "    def rolling_mean(self, arr: np.ndarray) -> np.ndarray:\n",
    "        return np.mean(arr)\n",
    "\n",
    "    def add_demographics(self) -> None:\n",
    "        \"\"\"\n",
    "        Merge selected demographic features into the training, validation, and test sets.\n",
    "        Encode them using one-hot encoding.\n",
    "        \"\"\"\n",
    "        # Columns to merge\n",
    "        columns_to_merge = [\n",
    "            'PtID', 'Gender', 'Ethnicity', 'Race', 'SHMostRec', 'SHNumLast12Mon', 'DKAMostRec', 'DKANumLast12Mon',\n",
    "            'OthGlucLowerMed', 'Weight', 'Height', 'PEAbnormal'\n",
    "        ]\n",
    "\n",
    "        # Filter the demographic set to include only the necessary columns\n",
    "        demographics = self.demographic_set[columns_to_merge]\n",
    "\n",
    "        # Prepare the encoder\n",
    "        encoder = OneHotEncoder(cols=['Gender', 'Ethnicity', 'Race', 'SHMostRec', 'SHNumLast12Mon', 'DKAMostRec', 'DKANumLast12Mon', 'OthGlucLowerMed', 'PEAbnormal'], use_cat_names=True)\n",
    "\n",
    "        # Fit and transform the encoder on the demographic data\n",
    "        demographics_encoded = encoder.fit_transform(demographics)\n",
    "\n",
    "        # Merge the encoded demographic data with each dataset\n",
    "        self.training_set = self.training_set.merge(demographics_encoded, how='left', left_on='id', right_on='PtID')\n",
    "        self.validation_set = self.validation_set.merge(demographics_encoded, how='left', left_on='id', right_on='PtID')\n",
    "        self.test_set = self.test_set.merge(demographics_encoded, how='left', left_on='id', right_on='PtID')\n",
    "\n",
    "    def aggregate_window(self, func: Callable, func_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Apply func over various window sizes and add columns to training and validation sets for the output of these aggregate functions\n",
    "        \n",
    "        Args:\n",
    "        func (Callable): A function to apply to each aggregate window.\n",
    "        func_name (str): The name of the function, used to create new column names.\n",
    "        \"\"\"\n",
    "        # Define the time intervals in minutes for aggregation\n",
    "        time_windows = {\n",
    "            'last_10_minutes': 10,\n",
    "            'last_30_minutes': 30,\n",
    "            'last_1_hour': 60,\n",
    "            'last_3_hours': 180,\n",
    "            'last_6_hours': 360,\n",
    "            'last_12_hours': 720\n",
    "        }\n",
    "\n",
    "        # Convert the column names to a format we can perform calculations on (number of minutes since 06:00:00)\n",
    "\n",
    "        stamps = self.training_set.columns[4:221]\n",
    "        \n",
    "        times = pd.to_timedelta(stamps).total_seconds()/60  # Convert to minutes\n",
    "\n",
    "        # Apply the aggregation function over specified time windows\n",
    "        for window_name, minutes in time_windows.items():\n",
    "            # Find the time range for each window\n",
    "            max_time = times.max()\n",
    "            min_time = max_time - minutes\n",
    "\n",
    "            # Get columns that fall within the current time window\n",
    "            columns_to_aggregate = [time for time in stamps if min_time < pd.to_timedelta(time).total_seconds()/60 <= max_time]\n",
    "\n",
    "            # For FFT, handle real and imaginary parts separately\n",
    "            if func == self.fft:\n",
    "                # Convert DataFrames to arrays before applying FFT\n",
    "                fft_results_train = np.apply_along_axis(func, 1, self.training_set[columns_to_aggregate].values)\n",
    "                fft_results_valid = np.apply_along_axis(func, 1, self.validation_set[columns_to_aggregate].values)\n",
    "                fft_results_test = np.apply_along_axis(func, 1, self.test_set[columns_to_aggregate].values)\n",
    "\n",
    "                for i in range(fft_results_train.shape[1]):\n",
    "                    self.training_set[f'{func_name}_{window_name}_real_{i}'] = fft_results_train[:, i].real\n",
    "                    self.training_set[f'{func_name}_{window_name}_imag_{i}'] = fft_results_train[:, i].imag\n",
    "                    self.validation_set[f'{func_name}_{window_name}_real_{i}'] = fft_results_valid[:, i].real\n",
    "                    self.validation_set[f'{func_name}_{window_name}_imag_{i}'] = fft_results_valid[:, i].imag\n",
    "                    self.test_set[f'{func_name}_{window_name}_real_{i}'] = fft_results_test[:, i].real\n",
    "                    self.test_set[f'{func_name}_{window_name}_imag_{i}'] = fft_results_test[:, i].imag\n",
    "            \n",
    "            else:\n",
    "                # Apply the function to the selected columns and store in a new column\n",
    "                self.training_set[f'{func_name}_{window_name}'] = self.training_set[columns_to_aggregate].apply(func, axis=1)\n",
    "                self.validation_set[f'{func_name}_{window_name}'] = self.validation_set[columns_to_aggregate].apply(func, axis=1)\n",
    "                self.test_set[f'{func_name}_{window_name}'] = self.test_set[columns_to_aggregate].apply(func, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/zxy_nmpx04gg6ssx89r9gl5h0000gn/T/ipykernel_7482/594277328.py:3: DtypeWarning: Columns (221) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.training_set = pd.read_csv(\"cleaned_data/train_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not convert 'corresponding_day' to NumPy timedelta",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32mtimedeltas.pyx:444\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.array_to_timedelta64\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimedeltas.pyx:476\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas._item_to_timedelta64_fastpath\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimedeltas.pyx:653\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.parse_timedelta_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unit abbreviation w/o a number",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32mtimedeltas.pyx:488\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas._item_to_timedelta64\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimedeltas.pyx:367\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.convert_to_timedelta64\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimedeltas.pyx:653\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.parse_timedelta_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unit abbreviation w/o a number",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mFeatureEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m, in \u001b[0;36mFeatureEngine.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdemographic_set \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Tables/HScreening.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, delimiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#self.time_series = pd.read_csv(\"Experimental_Notebooks/resampled_day.csv\")\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_window\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 87\u001b[0m, in \u001b[0;36mFeatureEngine.aggregate_window\u001b[0;34m(self, func, func_name)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Convert the column names to a format we can perform calculations on (number of minutes since 06:00:00)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m stamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_set\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m221\u001b[39m]\n\u001b[0;32m---> 87\u001b[0m times \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_timedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstamps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m  \u001b[38;5;66;03m# Convert to minutes\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Apply the aggregation function over specified time windows\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m window_name, minutes \u001b[38;5;129;01min\u001b[39;00m time_windows\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Find the time range for each window\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/core/tools/timedeltas.py:204\u001b[0m, in \u001b[0;36mto_timedelta\u001b[0;34m(arg, unit, errors)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCIndex):\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m# extract array scalar and process below\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"object\",\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# variable has type \"Union[str, int, float, timedelta, List[Any],\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# Tuple[Any, ...], Union[Union[ExtensionArray, ndarray[Any, Any]], Index,\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# Series]]\")  [assignment]\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     arg \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(arg)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/core/tools/timedeltas.py:266\u001b[0m, in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, unit, errors, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     td64arr \u001b[38;5;241m=\u001b[39m \u001b[43msequence_to_td64ns\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/core/arrays/timedeltas.py:1062\u001b[0m, in \u001b[0;36msequence_to_td64ns\u001b[0;34m(data, copy, unit, errors)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# Convert whatever we have into timedelta64[ns] dtype\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_string_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;66;03m# no need to make a copy, need to convert if string-dtyped\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_objects_to_td64ns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;66;03m# treat as multiples of the given unit\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/core/arrays/timedeltas.py:1191\u001b[0m, in \u001b[0;36m_objects_to_td64ns\u001b[0;34m(data, unit, errors)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# coerce Index to np.ndarray, converting string-dtype if necessary\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1191\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43marray_to_timedelta64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimedelta64[ns]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32mtimedeltas.pyx:458\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.array_to_timedelta64\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimedeltas.pyx:495\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas._item_to_timedelta64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not convert 'corresponding_day' to NumPy timedelta"
     ]
    }
   ],
   "source": [
    "test = FeatureEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest\u001b[49m\u001b[38;5;241m.\u001b[39mtraining_set\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m220\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "print(test.training_set.iloc[:, 220].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>corresponding_day</th>\n",
       "      <th>06:00:00</th>\n",
       "      <th>06:05:00</th>\n",
       "      <th>06:10:00</th>\n",
       "      <th>06:15:00</th>\n",
       "      <th>06:20:00</th>\n",
       "      <th>06:25:00</th>\n",
       "      <th>...</th>\n",
       "      <th>23:45:00</th>\n",
       "      <th>23:50:00</th>\n",
       "      <th>23:55:00</th>\n",
       "      <th>hypo</th>\n",
       "      <th>tar_last_10_minutes</th>\n",
       "      <th>tar_last_30_minutes</th>\n",
       "      <th>tar_last_1_hour</th>\n",
       "      <th>tar_last_3_hours</th>\n",
       "      <th>tar_last_6_hours</th>\n",
       "      <th>tar_last_12_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514</td>\n",
       "      <td>1514</td>\n",
       "      <td>15</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>125.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>...</td>\n",
       "      <td>186.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1515</td>\n",
       "      <td>1515</td>\n",
       "      <td>15</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>154.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.263889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1516</td>\n",
       "      <td>1516</td>\n",
       "      <td>15</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>115.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1517</td>\n",
       "      <td>1517</td>\n",
       "      <td>15</td>\n",
       "      <td>2015-04-26</td>\n",
       "      <td>227.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>322.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1518</td>\n",
       "      <td>1518</td>\n",
       "      <td>15</td>\n",
       "      <td>2015-04-27</td>\n",
       "      <td>172.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.534722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  id corresponding_day  06:00:00  06:05:00  06:10:00  \\\n",
       "0        1514   1514  15        2015-04-23     125.0     134.0     131.0   \n",
       "1        1515   1515  15        2015-04-24     154.0     156.0     159.0   \n",
       "2        1516   1516  15        2015-04-25     115.0     108.0      96.0   \n",
       "3        1517   1517  15        2015-04-26     227.0     228.0     229.0   \n",
       "4        1518   1518  15        2015-04-27     172.0     181.0     178.0   \n",
       "\n",
       "   06:15:00  06:20:00  06:25:00  ...  23:45:00  23:50:00  23:55:00   hypo  \\\n",
       "0     142.0     157.0     169.0  ...     186.0     180.0     173.0  False   \n",
       "1     158.0     161.0     143.0  ...     165.0     166.0     165.0   True   \n",
       "2      86.0      82.0      87.0  ...     162.0     165.0     167.0   True   \n",
       "3     231.0     240.0     244.0  ...     322.0     326.0     316.0   True   \n",
       "4     172.0     189.0     195.0  ...     126.0     123.0     115.0  False   \n",
       "\n",
       "   tar_last_10_minutes  tar_last_30_minutes  tar_last_1_hour  \\\n",
       "0                  0.0             0.666667         0.833333   \n",
       "1                  0.0             0.000000         0.000000   \n",
       "2                  0.0             0.000000         0.000000   \n",
       "3                  1.0             1.000000         1.000000   \n",
       "4                  0.0             0.000000         0.000000   \n",
       "\n",
       "   tar_last_3_hours  tar_last_6_hours  tar_last_12_hours  \n",
       "0          0.944444          0.638889           0.569444  \n",
       "1          0.527778          0.527778           0.263889  \n",
       "2          0.000000          0.069444           0.125000  \n",
       "3          1.000000          0.680556           0.625000  \n",
       "4          0.583333          0.444444           0.534722  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/zxy_nmpx04gg6ssx89r9gl5h0000gn/T/ipykernel_7482/1814562123.py:1: DtypeWarning: Columns (221) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  blah = pd.read_csv('cleaned_data/train_data.csv')\n"
     ]
    }
   ],
   "source": [
    "blah = pd.read_csv('cleaned_data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = blah.dropna(subset=[blah.columns[221]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'clean_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_data/train_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/io/formats/csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/io/common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 739\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FYP/REPLACE-BG/my-python3-env/lib/python3.9/site-packages/pandas/io/common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'clean_data'"
     ]
    }
   ],
   "source": [
    "clean.to_csv('cleaned_data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "2. Add Morlet Mexican Hat Columns\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
